{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-98T1e0Fo-_"
      },
      "source": [
        "# Introduction to Convolutional Neural Networks\n",
        "\n",
        "\n",
        "** Ecole Centrale Nantes **\n",
        "\n",
        "** Diana Mateus **\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWvMyUuIFo_F"
      },
      "source": [
        "** Participants : **\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbzD2vUXFo_J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sO2dQfUFo_L"
      },
      "source": [
        "### 0. Loading the dataset\n",
        "Start by runing the following lines to load and visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# UNCOMMENT IF USING COLAB\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "IMDIR = 'YOUR PATH'"
      ],
      "metadata": {
        "id": "tnoNobk1KaPM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMhp19cHFo_M"
      },
      "outputs": [],
      "source": [
        "def load_dataset(IMDIR):\n",
        "    train_dataset = h5py.File(IMDIR+'dataset/train_catvnoncat.h5', \"r\")\n",
        "    train_x = np.array(train_dataset[\"train_set_x\"][:])\n",
        "    train_y = np.array(train_dataset[\"train_set_y\"][:])\n",
        "    test_dataset = h5py.File(IMDIR+'dataset/test_catvnoncat.h5', \"r\")\n",
        "    test_x = np.array(test_dataset[\"test_set_x\"][:])\n",
        "    test_y = np.array(test_dataset[\"test_set_y\"][:])\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "\n",
        "    train_y = train_y.reshape((1, train_y.shape[0]))\n",
        "    test_y = test_y.reshape((1, test_y.shape[0]))\n",
        "\n",
        "    return train_x, train_y, test_x, test_y, classes\n",
        "\n",
        "train_x, train_y, test_x, test_y, classes=load_dataset(IMDIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKTEbV8Fo_O"
      },
      "source": [
        "#### Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XY74AXWEFo_O"
      },
      "outputs": [],
      "source": [
        "# run several times to visualize different data points\n",
        "# the title shows the ground truth class labels (0=no cat , 1 = cat)\n",
        "index = np.random.randint(low=0,high=train_y.shape[1])\n",
        "plt.imshow(train_x[index])\n",
        "plt.title(\"Image \"+str(index)+\" label \"+str(train_y[0,index]))\n",
        "plt.show()\n",
        "print (\"Train X shape: \" + str(train_x.shape))\n",
        "print (\"We have \"+str(train_x.shape[0]),\n",
        "       \"images of dimensionality \"\n",
        "       + str(train_x.shape[1])+ \"x\"\n",
        "       + str(train_x.shape[2])+ \"x\"\n",
        "       + str(train_x.shape[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SWukehhFo_g"
      },
      "source": [
        "### 1. CNNs with Keras and Tensorflow\n",
        "\n",
        "Adapt the example in this website https://keras.io/examples/vision/mnist_convnet/ to our problem. To this end:\n",
        "- change the number of classes and the input size\n",
        "- remove the expand_dims(x_train, -1): it is not necessary to expand the dimensions since our input has already three channels\n",
        "- you may need to transpose the labels vector\n",
        "- change the categorical cross-entropy to the binary cross entropy given that our problem is binary classification.\n",
        "- also change the softmax to sigmoid, the more appropriate activation function for binary data\n",
        "\n",
        "We can choose a single neuron output passed through sigmoid, and then set a threshold to choose the class, or use two neuron output and then perform a softmax.\n",
        "\n",
        "**2.2** Compute the train and test loss and accuracy after the model has been trained.  What model parameters does the ``fit`` function retain?\n",
        "\n",
        "**2.3** How many parameters does the network have, explain  the exact number .\n",
        "\n",
        "**2.4** Display and discuss the ROC curve of at least 3 different CNN configurations  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhzjC8_VFo_h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yv4lWad0Fo_j"
      },
      "outputs": [],
      "source": [
        "# the data, split between train and test sets\n",
        "x_train, y_train, x_test, y_test, classes=load_dataset()\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = y_train.T\n",
        "y_test = y_test.T\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rhgPycoVFo_l"
      },
      "outputs": [],
      "source": [
        "#build the model\n",
        "model =\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL0w6OeFFo_o"
      },
      "outputs": [],
      "source": [
        "#comiple and fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2LX_FTgzFo_p"
      },
      "outputs": [],
      "source": [
        "#evaluate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX_LrVY_Fo_q"
      },
      "source": [
        "## 2 Custom training loop (OPTIONAL ARTIN)\n",
        "Replace the fit function by your own tensorflow  implementation\n",
        "\n",
        "- Instantiate one of keras.optimizers to train the model.\n",
        "\n",
        "- Instantiate a loss from keras.losses\n",
        "\n",
        "- Define the metrics (from keras.metrics)\n",
        "\n",
        "- Use `tf.data.Dataset.from_tensor_slices` to create an iterable dataset from a numpy arrays. Do this for the training and test datasets.\n",
        "\n",
        "- Change the model (optional, after the training loop runs to optimize the performance)\n",
        "\n",
        "- Program a loop over a fixed number of epochs,\n",
        "    * For each epoch iterating over the batches\n",
        "    * Within a `GradientTape()` scope,\n",
        "      - do a forward pass on the model for the current batch (call the model on the batch data)\n",
        "      - Compute the loss\n",
        "      - Compute the gradients of the loss w.r.t parameters\n",
        "      - Call the optimimzer to update the weights with computed the gradients\n",
        "    * At the end of each epoch compute the validation metrics\n",
        "\n",
        "\n",
        "Look at https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough specifically at the TRAINING LOOP SECTION\n",
        "for a recent documentation on custom training.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uMeFjNH64CWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ADITIONAL BONUS\n",
        "- Early stopping\n",
        "- Tensorboard\n",
        "- CAM/GradCAM"
      ],
      "metadata": {
        "id": "zd77rWJY4Eon"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-PQ71UOFo_r"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf2",
      "language": "python",
      "name": "tf2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}