{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-98T1e0Fo-_"
      },
      "source": [
        "# Introduction to Convolutional Neural Networks\n",
        "\n",
        "\n",
        "** Ecole Centrale Nantes **\n",
        "\n",
        "** Diana Mateus **\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWvMyUuIFo_F"
      },
      "source": [
        "** Participants : **\n",
        "## Raphael Blanchard, So Onishi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BbzD2vUXFo_J"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sO2dQfUFo_L"
      },
      "source": [
        "### 0. Loading the dataset\n",
        "Start by runing the following lines to load and visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "tnoNobk1KaPM"
      },
      "outputs": [],
      "source": [
        "# UNCOMMENT IF USING COLAB\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "IMDIR = './dataset/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fMhp19cHFo_M"
      },
      "outputs": [],
      "source": [
        "def load_dataset(IMDIR):\n",
        "    train_dataset = h5py.File(IMDIR+'dataset/train_catvnoncat.h5', \"r\")\n",
        "    train_x = np.array(train_dataset[\"train_set_x\"][:])\n",
        "    train_y = np.array(train_dataset[\"train_set_y\"][:])\n",
        "    test_dataset = h5py.File(IMDIR+'dataset/test_catvnoncat.h5', \"r\")\n",
        "    test_x = np.array(test_dataset[\"test_set_x\"][:])\n",
        "    test_y = np.array(test_dataset[\"test_set_y\"][:])\n",
        "    classes = np.array(test_dataset[\"list_classes\"][:])\n",
        "\n",
        "    train_y = train_y.reshape((1, train_y.shape[0]))\n",
        "    test_y = test_y.reshape((1, test_y.shape[0]))\n",
        "\n",
        "    return train_x, train_y, test_x, test_y, classes\n",
        "\n",
        "train_x, train_y, test_x, test_y, classes=load_dataset(IMDIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRKTEbV8Fo_O"
      },
      "source": [
        "#### Visualize data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "XY74AXWEFo_O"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train X shape: (209, 64, 64, 3)\n",
            "We have 209 images of dimensionality 64x64x3\n"
          ]
        }
      ],
      "source": [
        "# run several times to visualize different data points\n",
        "# the title shows the ground truth class labels (0=no cat , 1 = cat)\n",
        "index = np.random.randint(low=0,high=train_y.shape[1])\n",
        "plt.imshow(train_x[index])\n",
        "plt.title(\"Image \"+str(index)+\" label \"+str(train_y[0,index]))\n",
        "plt.show()\n",
        "print (\"Train X shape: \" + str(train_x.shape))\n",
        "print (\"We have \"+str(train_x.shape[0]),\n",
        "       \"images of dimensionality \"\n",
        "       + str(train_x.shape[1])+ \"x\"\n",
        "       + str(train_x.shape[2])+ \"x\"\n",
        "       + str(train_x.shape[3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SWukehhFo_g"
      },
      "source": [
        "### 1. CNNs with Keras and Tensorflow\n",
        "\n",
        "Adapt the example in this website https://keras.io/examples/vision/mnist_convnet/ to our problem. To this end:\n",
        "- change the number of classes and the input size\n",
        "- remove the expand_dims(x_train, -1): it is not necessary to expand the dimensions since our input has already three channels\n",
        "- you may need to transpose the labels vector\n",
        "- change the categorical cross-entropy to the binary cross entropy given that our problem is binary classification.\n",
        "- also change the softmax to sigmoid, the more appropriate activation function for binary data\n",
        "\n",
        "We can choose a single neuron output passed through sigmoid, and then set a threshold to choose the class, or use two neuron output and then perform a softmax.\n",
        "\n",
        "**2.2** Compute the train and test loss and accuracy after the model has been trained.  What model parameters does the ``fit`` function retain?\n",
        "\n",
        "**2.3** How many parameters does the network have, explain  the exact number .\n",
        "\n",
        "**2.4** Display and discuss the ROC curve of at least 3 different CNN configurations  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nhzjC8_VFo_h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "yv4lWad0Fo_j"
      },
      "outputs": [],
      "source": [
        "# the data, split between train and test sets\n",
        "x_train, y_train, x_test, y_test, classes=load_dataset(IMDIR=IMDIR)\n",
        "\n",
        "num_classes = 2\n",
        "input_shape = (64, 64, 3)\n",
        "\n",
        "# Scale images to the [0, 1] range\n",
        "x_train = x_train.astype(\"float32\") / 255\n",
        "x_test = x_test.astype(\"float32\") / 255\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = y_train.T\n",
        "y_test = y_test.T\n",
        "\n",
        "non_onehot_y_test = y_test\n",
        "\n",
        "\n",
        "# doing the one hot encoding of our classes\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "rhgPycoVFo_l"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 31, 31, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 12544)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2)                 25090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,482\n",
            "Trainable params: 44,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "#build the model\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Number of params:\n",
        "\n",
        "44482 params\n",
        "\n",
        "Explanation in the report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "LL0w6OeFFo_o"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 187ms/step - loss: 0.6710 - accuracy: 0.5957 - val_loss: 0.5199 - val_accuracy: 0.8095\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.6486 - accuracy: 0.6383 - val_loss: 0.5335 - val_accuracy: 0.8095\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.6185 - accuracy: 0.6383 - val_loss: 0.5403 - val_accuracy: 0.8095\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5965 - accuracy: 0.6383 - val_loss: 0.5220 - val_accuracy: 0.8095\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5819 - accuracy: 0.6383 - val_loss: 0.5107 - val_accuracy: 0.8095\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5661 - accuracy: 0.6383 - val_loss: 0.5031 - val_accuracy: 0.8095\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.5479 - accuracy: 0.6436 - val_loss: 0.5158 - val_accuracy: 0.8095\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.5355 - accuracy: 0.6543 - val_loss: 0.4948 - val_accuracy: 0.8095\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.5225 - accuracy: 0.6436 - val_loss: 0.4830 - val_accuracy: 0.8095\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.5056 - accuracy: 0.6489 - val_loss: 0.4875 - val_accuracy: 0.7619\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.4841 - accuracy: 0.7287 - val_loss: 0.4795 - val_accuracy: 0.8095\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.4657 - accuracy: 0.7872 - val_loss: 0.4652 - val_accuracy: 0.8095\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 91ms/step - loss: 0.4399 - accuracy: 0.8245 - val_loss: 0.4615 - val_accuracy: 0.8095\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.4147 - accuracy: 0.8351 - val_loss: 0.4513 - val_accuracy: 0.8095\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.3959 - accuracy: 0.8351 - val_loss: 0.4599 - val_accuracy: 0.7619\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.3918 - accuracy: 0.8351 - val_loss: 0.4584 - val_accuracy: 0.8095\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 0.3697 - accuracy: 0.8032 - val_loss: 0.4552 - val_accuracy: 0.8095\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.3462 - accuracy: 0.8617 - val_loss: 0.4636 - val_accuracy: 0.7619\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.3253 - accuracy: 0.8777 - val_loss: 0.5346 - val_accuracy: 0.7619\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.3507 - accuracy: 0.8085 - val_loss: 0.4846 - val_accuracy: 0.7619\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.3508 - accuracy: 0.8670 - val_loss: 0.4653 - val_accuracy: 0.7619\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.3080 - accuracy: 0.8830 - val_loss: 0.5685 - val_accuracy: 0.7619\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.3221 - accuracy: 0.8404 - val_loss: 0.4905 - val_accuracy: 0.7619\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.3088 - accuracy: 0.8830 - val_loss: 0.5106 - val_accuracy: 0.7619\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.2931 - accuracy: 0.8936 - val_loss: 0.5672 - val_accuracy: 0.8095\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.2748 - accuracy: 0.8936 - val_loss: 0.5207 - val_accuracy: 0.7619\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.2674 - accuracy: 0.9255 - val_loss: 0.5423 - val_accuracy: 0.7619\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.2554 - accuracy: 0.8936 - val_loss: 0.5742 - val_accuracy: 0.7619\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.2481 - accuracy: 0.9043 - val_loss: 0.5242 - val_accuracy: 0.7143\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.2581 - accuracy: 0.9149 - val_loss: 0.5490 - val_accuracy: 0.7143\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.2226 - accuracy: 0.9309 - val_loss: 0.6457 - val_accuracy: 0.7619\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.2454 - accuracy: 0.8936 - val_loss: 0.5865 - val_accuracy: 0.7143\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.2417 - accuracy: 0.9149 - val_loss: 0.5800 - val_accuracy: 0.7143\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 106ms/step - loss: 0.2172 - accuracy: 0.9309 - val_loss: 0.6731 - val_accuracy: 0.7143\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.2237 - accuracy: 0.9149 - val_loss: 0.5668 - val_accuracy: 0.7143\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.2207 - accuracy: 0.9255 - val_loss: 0.5967 - val_accuracy: 0.7143\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.1960 - accuracy: 0.9468 - val_loss: 0.6690 - val_accuracy: 0.7619\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.2119 - accuracy: 0.9255 - val_loss: 0.6505 - val_accuracy: 0.7143\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.1904 - accuracy: 0.9468 - val_loss: 0.6775 - val_accuracy: 0.7143\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.1719 - accuracy: 0.9574 - val_loss: 0.6422 - val_accuracy: 0.6667\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.1764 - accuracy: 0.9468 - val_loss: 0.7024 - val_accuracy: 0.7619\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 109ms/step - loss: 0.1896 - accuracy: 0.9255 - val_loss: 0.6479 - val_accuracy: 0.6667\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 110ms/step - loss: 0.1806 - accuracy: 0.9362 - val_loss: 0.6479 - val_accuracy: 0.6667\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.1715 - accuracy: 0.9415 - val_loss: 0.7986 - val_accuracy: 0.7143\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.1951 - accuracy: 0.9309 - val_loss: 0.6444 - val_accuracy: 0.6667\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.1602 - accuracy: 0.9574 - val_loss: 0.6331 - val_accuracy: 0.6667\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.1675 - accuracy: 0.9468 - val_loss: 0.7210 - val_accuracy: 0.7619\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.1467 - accuracy: 0.9628 - val_loss: 0.6825 - val_accuracy: 0.6667\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.1402 - accuracy: 0.9521 - val_loss: 0.7009 - val_accuracy: 0.6667\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.1349 - accuracy: 0.9681 - val_loss: 0.7873 - val_accuracy: 0.6667\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.1413 - accuracy: 0.9574 - val_loss: 0.7332 - val_accuracy: 0.7143\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.1257 - accuracy: 0.9574 - val_loss: 0.7729 - val_accuracy: 0.7143\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.1479 - accuracy: 0.9521 - val_loss: 0.7078 - val_accuracy: 0.6667\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.1431 - accuracy: 0.9574 - val_loss: 0.7687 - val_accuracy: 0.6190\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.1292 - accuracy: 0.9681 - val_loss: 0.8510 - val_accuracy: 0.6667\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.1371 - accuracy: 0.9681 - val_loss: 0.7125 - val_accuracy: 0.7143\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.1384 - accuracy: 0.9521 - val_loss: 0.7009 - val_accuracy: 0.7143\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.1339 - accuracy: 0.9362 - val_loss: 0.7648 - val_accuracy: 0.7143\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.1122 - accuracy: 0.9681 - val_loss: 0.7389 - val_accuracy: 0.7143\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.1196 - accuracy: 0.9574 - val_loss: 0.8228 - val_accuracy: 0.6667\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0994 - accuracy: 0.9734 - val_loss: 0.8196 - val_accuracy: 0.6667\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0974 - accuracy: 0.9840 - val_loss: 0.8474 - val_accuracy: 0.6667\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0947 - accuracy: 0.9787 - val_loss: 0.8415 - val_accuracy: 0.6667\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0907 - accuracy: 0.9681 - val_loss: 0.8738 - val_accuracy: 0.7143\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0926 - accuracy: 0.9787 - val_loss: 0.8595 - val_accuracy: 0.7143\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0868 - accuracy: 0.9787 - val_loss: 0.8524 - val_accuracy: 0.7143\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0842 - accuracy: 0.9787 - val_loss: 0.8967 - val_accuracy: 0.7143\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0833 - accuracy: 0.9787 - val_loss: 0.8465 - val_accuracy: 0.7143\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0812 - accuracy: 0.9681 - val_loss: 0.8743 - val_accuracy: 0.7143\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0707 - accuracy: 0.9894 - val_loss: 0.9357 - val_accuracy: 0.7143\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0778 - accuracy: 0.9894 - val_loss: 0.8404 - val_accuracy: 0.7143\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0753 - accuracy: 0.9734 - val_loss: 0.8640 - val_accuracy: 0.7143\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0744 - accuracy: 0.9840 - val_loss: 0.8792 - val_accuracy: 0.7143\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0674 - accuracy: 0.9894 - val_loss: 0.8577 - val_accuracy: 0.7143\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0587 - accuracy: 0.9947 - val_loss: 0.9128 - val_accuracy: 0.7143\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0621 - accuracy: 0.9947 - val_loss: 0.8784 - val_accuracy: 0.7143\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0628 - accuracy: 0.9894 - val_loss: 0.8784 - val_accuracy: 0.7143\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0631 - accuracy: 0.9894 - val_loss: 0.9362 - val_accuracy: 0.7143\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0621 - accuracy: 0.9894 - val_loss: 0.8751 - val_accuracy: 0.7619\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0609 - accuracy: 0.9840 - val_loss: 0.9716 - val_accuracy: 0.7619\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0703 - accuracy: 0.9894 - val_loss: 0.9182 - val_accuracy: 0.7143\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0598 - accuracy: 0.9894 - val_loss: 0.8777 - val_accuracy: 0.7619\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0620 - accuracy: 0.9840 - val_loss: 1.0003 - val_accuracy: 0.7619\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0611 - accuracy: 0.9894 - val_loss: 0.9222 - val_accuracy: 0.7143\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0586 - accuracy: 0.9840 - val_loss: 0.8758 - val_accuracy: 0.7619\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0442 - accuracy: 0.9947 - val_loss: 1.0331 - val_accuracy: 0.7619\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0684 - accuracy: 0.9894 - val_loss: 0.9221 - val_accuracy: 0.7143\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0425 - accuracy: 1.0000 - val_loss: 0.9012 - val_accuracy: 0.7619\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0579 - accuracy: 0.9894 - val_loss: 0.9894 - val_accuracy: 0.7619\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0568 - accuracy: 0.9947 - val_loss: 0.9527 - val_accuracy: 0.7143\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0445 - accuracy: 0.9947 - val_loss: 0.9045 - val_accuracy: 0.7619\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0603 - accuracy: 0.9734 - val_loss: 0.9806 - val_accuracy: 0.7619\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0369 - accuracy: 1.0000 - val_loss: 0.9613 - val_accuracy: 0.7619\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0346 - accuracy: 1.0000 - val_loss: 0.9572 - val_accuracy: 0.7619\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0391 - accuracy: 0.9947 - val_loss: 0.9922 - val_accuracy: 0.7143\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0388 - accuracy: 1.0000 - val_loss: 1.0109 - val_accuracy: 0.7143\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0396 - accuracy: 1.0000 - val_loss: 1.0075 - val_accuracy: 0.7143\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0285 - accuracy: 1.0000 - val_loss: 1.0256 - val_accuracy: 0.7143\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0328 - accuracy: 0.9947 - val_loss: 0.9853 - val_accuracy: 0.7143\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0331 - accuracy: 0.9947 - val_loss: 1.0527 - val_accuracy: 0.7143\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0336 - accuracy: 1.0000 - val_loss: 1.0416 - val_accuracy: 0.7143\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 114ms/step - loss: 0.0255 - accuracy: 1.0000 - val_loss: 1.0101 - val_accuracy: 0.7143\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.0197 - val_accuracy: 0.7143\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0365 - accuracy: 1.0000 - val_loss: 1.0347 - val_accuracy: 0.7143\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0297 - accuracy: 0.9947 - val_loss: 1.0360 - val_accuracy: 0.7143\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 1.0149 - val_accuracy: 0.7143\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 1.0276 - val_accuracy: 0.7143\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0293 - accuracy: 1.0000 - val_loss: 1.0703 - val_accuracy: 0.7619\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 94ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 1.0245 - val_accuracy: 0.7143\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 1.0378 - val_accuracy: 0.7143\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0208 - accuracy: 1.0000 - val_loss: 1.0661 - val_accuracy: 0.7143\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 108ms/step - loss: 0.0276 - accuracy: 1.0000 - val_loss: 1.0387 - val_accuracy: 0.7143\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 143ms/step - loss: 0.0269 - accuracy: 1.0000 - val_loss: 1.0266 - val_accuracy: 0.7143\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 113ms/step - loss: 0.0207 - accuracy: 1.0000 - val_loss: 1.0162 - val_accuracy: 0.7619\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0243 - accuracy: 0.9947 - val_loss: 1.1253 - val_accuracy: 0.7619\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0305 - accuracy: 0.9947 - val_loss: 1.0295 - val_accuracy: 0.7619\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 112ms/step - loss: 0.0332 - accuracy: 0.9894 - val_loss: 1.0564 - val_accuracy: 0.7619\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 105ms/step - loss: 0.0286 - accuracy: 1.0000 - val_loss: 1.0607 - val_accuracy: 0.7619\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0227 - accuracy: 1.0000 - val_loss: 0.9938 - val_accuracy: 0.7619\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0307 - accuracy: 0.9894 - val_loss: 1.1101 - val_accuracy: 0.7619\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.1690 - val_accuracy: 0.7619\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.0248 - accuracy: 1.0000 - val_loss: 1.0413 - val_accuracy: 0.7143\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0221 - accuracy: 0.9947 - val_loss: 1.0526 - val_accuracy: 0.7143\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 1.1198 - val_accuracy: 0.7619\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 1.1084 - val_accuracy: 0.7143\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0162 - accuracy: 1.0000 - val_loss: 1.0682 - val_accuracy: 0.7143\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 1.0700 - val_accuracy: 0.7143\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0163 - accuracy: 1.0000 - val_loss: 1.1277 - val_accuracy: 0.7619\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 96ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 1.0942 - val_accuracy: 0.7143\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.0723 - val_accuracy: 0.7619\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 103ms/step - loss: 0.0198 - accuracy: 1.0000 - val_loss: 1.1557 - val_accuracy: 0.7619\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 1.2104 - val_accuracy: 0.7619\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 1.0837 - val_accuracy: 0.7619\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 1.0794 - val_accuracy: 0.7619\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0205 - accuracy: 0.9947 - val_loss: 1.1982 - val_accuracy: 0.7619\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 111ms/step - loss: 0.0168 - accuracy: 1.0000 - val_loss: 1.1642 - val_accuracy: 0.7619\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 1.0941 - val_accuracy: 0.7619\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 1.0960 - val_accuracy: 0.7619\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0160 - accuracy: 1.0000 - val_loss: 1.1763 - val_accuracy: 0.7619\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1900 - val_accuracy: 0.7619\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 1.1098 - val_accuracy: 0.7619\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 1.1270 - val_accuracy: 0.7143\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.2099 - val_accuracy: 0.7619\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 1.1948 - val_accuracy: 0.7619\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 1.1567 - val_accuracy: 0.7143\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.1597 - val_accuracy: 0.7143\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.2363 - val_accuracy: 0.7619\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.1992 - val_accuracy: 0.7619\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 1.1539 - val_accuracy: 0.7619\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 1.1845 - val_accuracy: 0.7143\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 1.2127 - val_accuracy: 0.7619\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 1.1470 - val_accuracy: 0.7619\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 98ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 1.1356 - val_accuracy: 0.7619\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0141 - accuracy: 1.0000 - val_loss: 1.2585 - val_accuracy: 0.7619\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0148 - accuracy: 1.0000 - val_loss: 1.2600 - val_accuracy: 0.7619\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 115ms/step - loss: 0.0114 - accuracy: 1.0000 - val_loss: 1.1373 - val_accuracy: 0.7619\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0151 - accuracy: 1.0000 - val_loss: 1.1515 - val_accuracy: 0.7619\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 1.3008 - val_accuracy: 0.7619\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0138 - accuracy: 1.0000 - val_loss: 1.2634 - val_accuracy: 0.7619\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.1522 - val_accuracy: 0.7619\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0112 - accuracy: 1.0000 - val_loss: 1.1637 - val_accuracy: 0.7143\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 1.2618 - val_accuracy: 0.7619\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 1.2612 - val_accuracy: 0.7619\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 1.1724 - val_accuracy: 0.7619\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0108 - accuracy: 1.0000 - val_loss: 1.1674 - val_accuracy: 0.7619\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2089 - val_accuracy: 0.7619\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 84ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.2516 - val_accuracy: 0.7619\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 1.2061 - val_accuracy: 0.7619\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.2130 - val_accuracy: 0.7619\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 1.2780 - val_accuracy: 0.7619\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2840 - val_accuracy: 0.7619\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.2106 - val_accuracy: 0.7619\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 1.2020 - val_accuracy: 0.7619\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 1.3125 - val_accuracy: 0.7619\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0098 - accuracy: 1.0000 - val_loss: 1.2847 - val_accuracy: 0.7619\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.2213 - val_accuracy: 0.7619\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 86ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 1.2172 - val_accuracy: 0.7619\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0071 - accuracy: 1.0000 - val_loss: 1.2565 - val_accuracy: 0.7619\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2972 - val_accuracy: 0.7619\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2677 - val_accuracy: 0.7619\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 1.2320 - val_accuracy: 0.7619\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 1.2551 - val_accuracy: 0.7619\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 92ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.3357 - val_accuracy: 0.7619\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 87ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.3270 - val_accuracy: 0.7619\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 1.2604 - val_accuracy: 0.7619\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 104ms/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 1.2635 - val_accuracy: 0.7619\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 1.3224 - val_accuracy: 0.7619\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 85ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 1.3538 - val_accuracy: 0.7619\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 1.2874 - val_accuracy: 0.7619\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 1.2691 - val_accuracy: 0.7619\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 1.3584 - val_accuracy: 0.7619\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 102ms/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 1.4008 - val_accuracy: 0.7619\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 101ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 1.2795 - val_accuracy: 0.7619\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 1.2531 - val_accuracy: 0.7619\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0097 - accuracy: 1.0000 - val_loss: 1.3432 - val_accuracy: 0.7619\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 93ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 1.3698 - val_accuracy: 0.7619\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 1.2853 - val_accuracy: 0.8095\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 89ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 1.2500 - val_accuracy: 0.7619\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 90ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.2889 - val_accuracy: 0.7619\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 95ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 1.3868 - val_accuracy: 0.7619\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x23aa5dc2ce0>"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compile and fit\n",
        "batch_size = 128\n",
        "epochs = 200\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "2LX_FTgzFo_p"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.14338696002960205  /\\ Train accuracy: 0.9760765433311462\n",
            "Test loss: 1.0969929695129395 /\\ Test accuracy: 0.8199999928474426\n"
          ]
        }
      ],
      "source": [
        "#evaluate\n",
        "training_score = model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Train loss:\", training_score[0], \" /\\ Train accuracy:\", training_score[1])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0], \"/\\ Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 62, 62, 32)        0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 31, 31, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 29, 29, 64)        18496     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 29, 29, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 12544)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 2)                 25090     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 44,482\n",
            "Trainable params: 44,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Defining other models\n",
        "# We saw there was a big difference between the training and val accuracy, meaning we lack generalization\n",
        "\n",
        "model2 = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.Dropout(0.25),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 221ms/step - loss: 0.7094 - accuracy: 0.5266 - val_loss: 0.5629 - val_accuracy: 0.8095\n",
            "Epoch 2/50\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.6743 - accuracy: 0.6383 - val_loss: 0.5982 - val_accuracy: 0.8095\n",
            "Epoch 3/50\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.6279 - accuracy: 0.6383 - val_loss: 0.6021 - val_accuracy: 0.8095\n",
            "Epoch 4/50\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 0.6052 - accuracy: 0.6383 - val_loss: 0.5549 - val_accuracy: 0.8095\n",
            "Epoch 5/50\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 0.5825 - accuracy: 0.6383 - val_loss: 0.5439 - val_accuracy: 0.8095\n",
            "Epoch 6/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.5417 - accuracy: 0.6436 - val_loss: 0.5254 - val_accuracy: 0.8095\n",
            "Epoch 7/50\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 0.5118 - accuracy: 0.6702 - val_loss: 0.5199 - val_accuracy: 0.7619\n",
            "Epoch 8/50\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.4795 - accuracy: 0.7500 - val_loss: 0.4955 - val_accuracy: 0.7619\n",
            "Epoch 9/50\n",
            "2/2 [==============================] - 0s 124ms/step - loss: 0.4499 - accuracy: 0.8138 - val_loss: 0.4804 - val_accuracy: 0.7143\n",
            "Epoch 10/50\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.4439 - accuracy: 0.7872 - val_loss: 0.4723 - val_accuracy: 0.7143\n",
            "Epoch 11/50\n",
            "2/2 [==============================] - 0s 140ms/step - loss: 0.4165 - accuracy: 0.7766 - val_loss: 0.4661 - val_accuracy: 0.7143\n",
            "Epoch 12/50\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 0.3892 - accuracy: 0.8191 - val_loss: 0.5034 - val_accuracy: 0.7619\n",
            "Epoch 13/50\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 0.3974 - accuracy: 0.8298 - val_loss: 0.4648 - val_accuracy: 0.7619\n",
            "Epoch 14/50\n",
            "2/2 [==============================] - 0s 134ms/step - loss: 0.3614 - accuracy: 0.8564 - val_loss: 0.4631 - val_accuracy: 0.7143\n",
            "Epoch 15/50\n",
            "2/2 [==============================] - 0s 132ms/step - loss: 0.3479 - accuracy: 0.8670 - val_loss: 0.4821 - val_accuracy: 0.7619\n",
            "Epoch 16/50\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.3412 - accuracy: 0.8511 - val_loss: 0.4720 - val_accuracy: 0.7143\n",
            "Epoch 17/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.3337 - accuracy: 0.8351 - val_loss: 0.4770 - val_accuracy: 0.7143\n",
            "Epoch 18/50\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 0.3198 - accuracy: 0.8511 - val_loss: 0.5015 - val_accuracy: 0.7619\n",
            "Epoch 19/50\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 0.3144 - accuracy: 0.8777 - val_loss: 0.4863 - val_accuracy: 0.7619\n",
            "Epoch 20/50\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.3191 - accuracy: 0.8617 - val_loss: 0.4898 - val_accuracy: 0.7619\n",
            "Epoch 21/50\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.2790 - accuracy: 0.9043 - val_loss: 0.5235 - val_accuracy: 0.7619\n",
            "Epoch 22/50\n",
            "2/2 [==============================] - 0s 138ms/step - loss: 0.3049 - accuracy: 0.8883 - val_loss: 0.4950 - val_accuracy: 0.7143\n",
            "Epoch 23/50\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.2878 - accuracy: 0.8670 - val_loss: 0.4973 - val_accuracy: 0.7143\n",
            "Epoch 24/50\n",
            "2/2 [==============================] - 0s 130ms/step - loss: 0.2811 - accuracy: 0.8936 - val_loss: 0.5123 - val_accuracy: 0.7143\n",
            "Epoch 25/50\n",
            "2/2 [==============================] - 0s 129ms/step - loss: 0.2641 - accuracy: 0.9149 - val_loss: 0.5022 - val_accuracy: 0.7143\n",
            "Epoch 26/50\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.2561 - accuracy: 0.8989 - val_loss: 0.5056 - val_accuracy: 0.7143\n",
            "Epoch 27/50\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 0.2358 - accuracy: 0.9202 - val_loss: 0.5320 - val_accuracy: 0.7143\n",
            "Epoch 28/50\n",
            "2/2 [==============================] - 0s 141ms/step - loss: 0.2609 - accuracy: 0.9096 - val_loss: 0.5173 - val_accuracy: 0.7143\n",
            "Epoch 29/50\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 0.2256 - accuracy: 0.9415 - val_loss: 0.5299 - val_accuracy: 0.6667\n",
            "Epoch 30/50\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 0.2340 - accuracy: 0.9149 - val_loss: 0.5274 - val_accuracy: 0.6667\n",
            "Epoch 31/50\n",
            "2/2 [==============================] - 0s 122ms/step - loss: 0.2134 - accuracy: 0.9309 - val_loss: 0.5382 - val_accuracy: 0.6667\n",
            "Epoch 32/50\n",
            "2/2 [==============================] - 0s 145ms/step - loss: 0.2195 - accuracy: 0.9043 - val_loss: 0.5354 - val_accuracy: 0.6667\n",
            "Epoch 33/50\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 0.2086 - accuracy: 0.9415 - val_loss: 0.5381 - val_accuracy: 0.6667\n",
            "Epoch 34/50\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.1809 - accuracy: 0.9362 - val_loss: 0.5499 - val_accuracy: 0.6190\n",
            "Epoch 35/50\n",
            "2/2 [==============================] - 0s 144ms/step - loss: 0.1946 - accuracy: 0.9309 - val_loss: 0.5442 - val_accuracy: 0.6667\n",
            "Epoch 36/50\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.1746 - accuracy: 0.9521 - val_loss: 0.5513 - val_accuracy: 0.6667\n",
            "Epoch 37/50\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.1814 - accuracy: 0.9362 - val_loss: 0.5555 - val_accuracy: 0.6667\n",
            "Epoch 38/50\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.1652 - accuracy: 0.9521 - val_loss: 0.5594 - val_accuracy: 0.6667\n",
            "Epoch 39/50\n",
            "2/2 [==============================] - 0s 131ms/step - loss: 0.1651 - accuracy: 0.9521 - val_loss: 0.5673 - val_accuracy: 0.6667\n",
            "Epoch 40/50\n",
            "2/2 [==============================] - 0s 123ms/step - loss: 0.1648 - accuracy: 0.9521 - val_loss: 0.5607 - val_accuracy: 0.6667\n",
            "Epoch 41/50\n",
            "2/2 [==============================] - 0s 128ms/step - loss: 0.1414 - accuracy: 0.9574 - val_loss: 0.5687 - val_accuracy: 0.7143\n",
            "Epoch 42/50\n",
            "2/2 [==============================] - 0s 125ms/step - loss: 0.1333 - accuracy: 0.9574 - val_loss: 0.5819 - val_accuracy: 0.7143\n",
            "Epoch 43/50\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 0.1321 - accuracy: 0.9628 - val_loss: 0.5960 - val_accuracy: 0.6667\n",
            "Epoch 44/50\n",
            "2/2 [==============================] - 0s 126ms/step - loss: 0.1269 - accuracy: 0.9681 - val_loss: 0.6035 - val_accuracy: 0.6667\n",
            "Epoch 45/50\n",
            "2/2 [==============================] - 0s 127ms/step - loss: 0.1287 - accuracy: 0.9628 - val_loss: 0.6120 - val_accuracy: 0.6667\n",
            "Epoch 46/50\n",
            "2/2 [==============================] - 0s 139ms/step - loss: 0.1286 - accuracy: 0.9628 - val_loss: 0.6114 - val_accuracy: 0.7143\n",
            "Epoch 47/50\n",
            "2/2 [==============================] - 0s 133ms/step - loss: 0.1207 - accuracy: 0.9574 - val_loss: 0.6103 - val_accuracy: 0.7143\n",
            "Epoch 48/50\n",
            "2/2 [==============================] - 0s 135ms/step - loss: 0.1240 - accuracy: 0.9681 - val_loss: 0.6209 - val_accuracy: 0.7143\n",
            "Epoch 49/50\n",
            "2/2 [==============================] - 0s 142ms/step - loss: 0.1201 - accuracy: 0.9628 - val_loss: 0.6301 - val_accuracy: 0.7143\n",
            "Epoch 50/50\n",
            "2/2 [==============================] - 0s 145ms/step - loss: 0.1097 - accuracy: 0.9628 - val_loss: 0.6515 - val_accuracy: 0.7143\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x23a83c670a0>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compile and fit\n",
        "batch_size = 128\n",
        "epochs = 50\n",
        "\n",
        "model2.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model2.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.20309080183506012  /\\ Train accuracy: 0.9569377899169922\n",
            "Test loss: 0.4771917760372162 /\\ Test accuracy: 0.800000011920929\n"
          ]
        }
      ],
      "source": [
        "#evaluate\n",
        "training_score = model2.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Train loss:\", training_score[0], \" /\\ Train accuracy:\", training_score[1])\n",
        "score = model2.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0], \"/\\ Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2 results\n",
        "\n",
        "We can see that by simply adding 2 dropout layers which will help with regularization, we go from 0.71 val acc to 0.81"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 64)        36928     \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 16, 16, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 256)       295168    \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 8, 8, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 32768)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               4194432   \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,808,322\n",
            "Trainable params: 5,808,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model3 = keras.Sequential([\n",
        "    keras.Input(shape=input_shape),\n",
        "    layers.Conv2D(32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
        "    layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=input_shape),\n",
        "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "    \n",
        "    layers.Conv2D(64, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    layers.Conv2D(128, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "    layers.Dropout(0.25),\n",
        "\n",
        "\n",
        "    layers.Conv2D(256, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    layers.Conv2D(512, kernel_size=3, strides=1, padding='same', activation='relu'),\n",
        "    layers.MaxPooling2D(pool_size=2, strides=2),\n",
        "    \n",
        "    layers.Flatten(),\n",
        "    \n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dropout(0.1),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dropout(0.5),\n",
        "    layers.Dense(num_classes, activation='sigmoid')\n",
        "])\n",
        "\n",
        "model3.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "6/6 [==============================] - 4s 422ms/step - loss: 0.6854 - accuracy: 0.6170 - val_loss: 0.6056 - val_accuracy: 0.8095\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 2s 392ms/step - loss: 0.6520 - accuracy: 0.6223 - val_loss: 0.6263 - val_accuracy: 0.8095\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 2s 391ms/step - loss: 0.5911 - accuracy: 0.6330 - val_loss: 0.5729 - val_accuracy: 0.8095\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 2s 373ms/step - loss: 0.5520 - accuracy: 0.6383 - val_loss: 0.6057 - val_accuracy: 0.8095\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 2s 377ms/step - loss: 0.4970 - accuracy: 0.6383 - val_loss: 0.6391 - val_accuracy: 0.8095\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 2s 368ms/step - loss: 0.4453 - accuracy: 0.6543 - val_loss: 0.6606 - val_accuracy: 0.8095\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 2s 380ms/step - loss: 0.4684 - accuracy: 0.7021 - val_loss: 0.6936 - val_accuracy: 0.8095\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 2s 389ms/step - loss: 0.4487 - accuracy: 0.7926 - val_loss: 1.2001 - val_accuracy: 0.9048\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 2s 369ms/step - loss: 0.3909 - accuracy: 0.7766 - val_loss: 0.9829 - val_accuracy: 0.7143\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 2s 386ms/step - loss: 0.4095 - accuracy: 0.8138 - val_loss: 0.9219 - val_accuracy: 0.7619\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 3s 427ms/step - loss: 0.3923 - accuracy: 0.8032 - val_loss: 0.8085 - val_accuracy: 0.8571\n",
            "Epoch 12/30\n",
            "6/6 [==============================] - 2s 381ms/step - loss: 0.4000 - accuracy: 0.8351 - val_loss: 1.1410 - val_accuracy: 0.7619\n",
            "Epoch 13/30\n",
            "6/6 [==============================] - 2s 390ms/step - loss: 0.3990 - accuracy: 0.8670 - val_loss: 1.0001 - val_accuracy: 0.7619\n",
            "Epoch 14/30\n",
            "6/6 [==============================] - 2s 385ms/step - loss: 0.3889 - accuracy: 0.8457 - val_loss: 1.1243 - val_accuracy: 0.8095\n",
            "Epoch 15/30\n",
            "6/6 [==============================] - 2s 384ms/step - loss: 0.3703 - accuracy: 0.8032 - val_loss: 0.9343 - val_accuracy: 0.8571\n",
            "Epoch 16/30\n",
            "6/6 [==============================] - 2s 372ms/step - loss: 0.3620 - accuracy: 0.8511 - val_loss: 1.0761 - val_accuracy: 0.8095\n",
            "Epoch 17/30\n",
            "6/6 [==============================] - 2s 375ms/step - loss: 0.3447 - accuracy: 0.8564 - val_loss: 1.0098 - val_accuracy: 0.7143\n",
            "Epoch 18/30\n",
            "6/6 [==============================] - 2s 391ms/step - loss: 0.3106 - accuracy: 0.8723 - val_loss: 0.8638 - val_accuracy: 0.7619\n",
            "Epoch 19/30\n",
            "6/6 [==============================] - 2s 373ms/step - loss: 0.2991 - accuracy: 0.8883 - val_loss: 1.6482 - val_accuracy: 0.8571\n",
            "Epoch 20/30\n",
            "6/6 [==============================] - 2s 365ms/step - loss: 0.3905 - accuracy: 0.8351 - val_loss: 0.9881 - val_accuracy: 0.6190\n",
            "Epoch 21/30\n",
            "6/6 [==============================] - 2s 369ms/step - loss: 0.4128 - accuracy: 0.8564 - val_loss: 0.7954 - val_accuracy: 0.6667\n",
            "Epoch 22/30\n",
            "6/6 [==============================] - 2s 405ms/step - loss: 0.3819 - accuracy: 0.8191 - val_loss: 0.6635 - val_accuracy: 0.7619\n",
            "Epoch 23/30\n",
            "6/6 [==============================] - 2s 410ms/step - loss: 0.3435 - accuracy: 0.8457 - val_loss: 0.7981 - val_accuracy: 0.8095\n",
            "Epoch 24/30\n",
            "6/6 [==============================] - 2s 395ms/step - loss: 0.3137 - accuracy: 0.8723 - val_loss: 0.8637 - val_accuracy: 0.8571\n",
            "Epoch 25/30\n",
            "6/6 [==============================] - 2s 372ms/step - loss: 0.2788 - accuracy: 0.8883 - val_loss: 0.9607 - val_accuracy: 0.8571\n",
            "Epoch 26/30\n",
            "6/6 [==============================] - 2s 374ms/step - loss: 0.2789 - accuracy: 0.8777 - val_loss: 0.9893 - val_accuracy: 0.8571\n",
            "Epoch 27/30\n",
            "6/6 [==============================] - 2s 376ms/step - loss: 0.2742 - accuracy: 0.8883 - val_loss: 0.7334 - val_accuracy: 0.8095\n",
            "Epoch 28/30\n",
            "6/6 [==============================] - 2s 391ms/step - loss: 0.2558 - accuracy: 0.8989 - val_loss: 2.2699 - val_accuracy: 0.8095\n",
            "Epoch 29/30\n",
            "6/6 [==============================] - 2s 401ms/step - loss: 0.3436 - accuracy: 0.8404 - val_loss: 0.8418 - val_accuracy: 0.7143\n",
            "Epoch 30/30\n",
            "6/6 [==============================] - 2s 392ms/step - loss: 0.2910 - accuracy: 0.8777 - val_loss: 2.7807 - val_accuracy: 0.8571\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x23aa65ec400>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#compile and fit\n",
        "batch_size = 32\n",
        "epochs = 30\n",
        "\n",
        "model3.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model3.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.5310593843460083  /\\ Train accuracy: 0.8755980730056763\n",
            "Test loss: 2.174846887588501 /\\ Test accuracy: 0.8199999928474426\n"
          ]
        }
      ],
      "source": [
        "#evaluate\n",
        "training_score = model3.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Train loss:\", training_score[0], \" /\\ Train accuracy:\", training_score[1])\n",
        "score = model3.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0], \"/\\ Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add\n",
        "\n",
        "def resnet_block(x, filters, kernel_size=3, stride=1):\n",
        "    # Shortcut\n",
        "    shortcut = x\n",
        "    \n",
        "    # First convolution layer\n",
        "    x = Conv2D(filters[0], kernel_size=(1, 1), strides=(stride, stride), padding='valid')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # Second convolution layer\n",
        "    x = Conv2D(filters[1], kernel_size=(kernel_size, kernel_size), strides=(1, 1), padding='same')(x)\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    # Third convolution layer\n",
        "    x = Conv2D(filters[2], kernel_size=(1, 1), strides=(1, 1), padding='valid')(x)\n",
        "    \n",
        "    # Shortcut connection\n",
        "    shortcut = Conv2D(filters[2], kernel_size=(1, 1), strides=(stride, stride), padding='valid')(shortcut)\n",
        "    \n",
        "    # Add shortcut and main path\n",
        "    x = Add()([x, shortcut])\n",
        "    x = Activation('relu')(x)\n",
        "    \n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_4 (InputLayer)           [(None, 64, 64, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 32, 32, 64)   9472        ['input_4[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 32, 32, 64)   0           ['conv2d_10[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 32, 32, 64)   4160        ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 32, 32, 64)   0           ['conv2d_11[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 32, 32, 64)   36928       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 32, 64)   0           ['conv2d_12[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 32, 32, 256)  16640       ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 32, 256)  16640       ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 32, 32, 256)  0           ['conv2d_13[0][0]',              \n",
            "                                                                  'conv2d_14[0][0]']              \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 32, 256)  0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 32, 64)   16448       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 32, 32, 64)   0           ['conv2d_15[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 32, 32, 64)   36928       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 32, 32, 64)   0           ['conv2d_16[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 32, 32, 256)  16640       ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 32, 32, 256)  65792       ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 32, 32, 256)  0           ['conv2d_17[0][0]',              \n",
            "                                                                  'conv2d_18[0][0]']              \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 32, 32, 256)  0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)             (None, 16, 16, 128)  32896       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 16, 16, 128)  0           ['conv2d_19[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)             (None, 16, 16, 128)  147584      ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 16, 16, 128)  0           ['conv2d_20[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 16, 16, 512)  66048       ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 16, 16, 512)  131584      ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 16, 16, 512)  0           ['conv2d_21[0][0]',              \n",
            "                                                                  'conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 16, 16, 512)  0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " global_average_pooling2d (Glob  (None, 512)         0           ['activation_9[0][0]']           \n",
            " alAveragePooling2D)                                                                              \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 2)            1026        ['global_average_pooling2d[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 598,786\n",
            "Trainable params: 598,786\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "input_layer = keras.Input(shape=input_shape)\n",
        "\n",
        "# Initial Convolutional layer\n",
        "x = layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2), padding='same')(input_layer)\n",
        "x = layers.Activation('relu')(x)\n",
        "\n",
        "# ResNet Blocks\n",
        "x = resnet_block(x, filters=[64, 64, 256], stride=1)\n",
        "x = resnet_block(x, filters=[64, 64, 256], stride=1)\n",
        "x = resnet_block(x, filters=[128, 128, 512], stride=2)\n",
        "\n",
        "# Global Average Pooling\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "# Output layer\n",
        "output_layer = layers.Dense(num_classes, activation='sigmoid')(x)  # 2 classes for binary classification\n",
        "\n",
        "# Create the model\n",
        "resnet_model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "resnet_model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2/2 [==============================] - 3s 659ms/step - loss: 0.6908 - accuracy: 0.6383 - val_loss: 0.6143 - val_accuracy: 0.8095\n",
            "Epoch 2/30\n",
            "2/2 [==============================] - 1s 511ms/step - loss: 0.6569 - accuracy: 0.6383 - val_loss: 0.5340 - val_accuracy: 0.8095\n",
            "Epoch 3/30\n",
            "2/2 [==============================] - 1s 512ms/step - loss: 0.6565 - accuracy: 0.6383 - val_loss: 0.5662 - val_accuracy: 0.8095\n",
            "Epoch 4/30\n",
            "2/2 [==============================] - 1s 501ms/step - loss: 0.6403 - accuracy: 0.6383 - val_loss: 0.5621 - val_accuracy: 0.8095\n",
            "Epoch 5/30\n",
            "2/2 [==============================] - 1s 579ms/step - loss: 0.6256 - accuracy: 0.6383 - val_loss: 0.5465 - val_accuracy: 0.8095\n",
            "Epoch 6/30\n",
            "2/2 [==============================] - 2s 518ms/step - loss: 0.5991 - accuracy: 0.6383 - val_loss: 0.5052 - val_accuracy: 0.8095\n",
            "Epoch 7/30\n",
            "2/2 [==============================] - 1s 497ms/step - loss: 0.5547 - accuracy: 0.6383 - val_loss: 0.5131 - val_accuracy: 0.8095\n",
            "Epoch 8/30\n",
            "2/2 [==============================] - 2s 513ms/step - loss: 0.5597 - accuracy: 0.6383 - val_loss: 0.5339 - val_accuracy: 0.8095\n",
            "Epoch 9/30\n",
            "2/2 [==============================] - 2s 629ms/step - loss: 0.5626 - accuracy: 0.6383 - val_loss: 0.5324 - val_accuracy: 0.8095\n",
            "Epoch 10/30\n",
            "2/2 [==============================] - 2s 527ms/step - loss: 0.5126 - accuracy: 0.6383 - val_loss: 0.5816 - val_accuracy: 0.8095\n",
            "Epoch 11/30\n",
            "2/2 [==============================] - 2s 517ms/step - loss: 0.4691 - accuracy: 0.6596 - val_loss: 0.6397 - val_accuracy: 0.7143\n",
            "Epoch 12/30\n",
            "2/2 [==============================] - 1s 514ms/step - loss: 0.4455 - accuracy: 0.7766 - val_loss: 0.7626 - val_accuracy: 0.7143\n",
            "Epoch 13/30\n",
            "2/2 [==============================] - 2s 547ms/step - loss: 0.4445 - accuracy: 0.7979 - val_loss: 0.7496 - val_accuracy: 0.7143\n",
            "Epoch 14/30\n",
            "2/2 [==============================] - 2s 560ms/step - loss: 0.4305 - accuracy: 0.8298 - val_loss: 0.7428 - val_accuracy: 0.7619\n",
            "Epoch 15/30\n",
            "2/2 [==============================] - 2s 585ms/step - loss: 0.4626 - accuracy: 0.7500 - val_loss: 0.6827 - val_accuracy: 0.6667\n",
            "Epoch 16/30\n",
            "2/2 [==============================] - 2s 554ms/step - loss: 0.4674 - accuracy: 0.7766 - val_loss: 0.7021 - val_accuracy: 0.3333\n",
            "Epoch 17/30\n",
            "2/2 [==============================] - 2s 609ms/step - loss: 0.5723 - accuracy: 0.6755 - val_loss: 0.6798 - val_accuracy: 0.3333\n",
            "Epoch 18/30\n",
            "2/2 [==============================] - 2s 587ms/step - loss: 0.5300 - accuracy: 0.7128 - val_loss: 0.7165 - val_accuracy: 0.7619\n",
            "Epoch 19/30\n",
            "2/2 [==============================] - 2s 592ms/step - loss: 0.5272 - accuracy: 0.6968 - val_loss: 0.8027 - val_accuracy: 0.8095\n",
            "Epoch 20/30\n",
            "2/2 [==============================] - 2s 564ms/step - loss: 0.4253 - accuracy: 0.7606 - val_loss: 0.7219 - val_accuracy: 0.6190\n",
            "Epoch 21/30\n",
            "2/2 [==============================] - 2s 537ms/step - loss: 0.4366 - accuracy: 0.8085 - val_loss: 0.7135 - val_accuracy: 0.5238\n",
            "Epoch 22/30\n",
            "2/2 [==============================] - 2s 566ms/step - loss: 0.4823 - accuracy: 0.7447 - val_loss: 0.7556 - val_accuracy: 0.6190\n",
            "Epoch 23/30\n",
            "2/2 [==============================] - 1s 517ms/step - loss: 0.4312 - accuracy: 0.8138 - val_loss: 1.1079 - val_accuracy: 0.8571\n",
            "Epoch 24/30\n",
            "2/2 [==============================] - 2s 553ms/step - loss: 0.4455 - accuracy: 0.7872 - val_loss: 0.7860 - val_accuracy: 0.6190\n",
            "Epoch 25/30\n",
            "2/2 [==============================] - 2s 570ms/step - loss: 0.4233 - accuracy: 0.8032 - val_loss: 0.7484 - val_accuracy: 0.5714\n",
            "Epoch 26/30\n",
            "2/2 [==============================] - 2s 553ms/step - loss: 0.4301 - accuracy: 0.7979 - val_loss: 0.7638 - val_accuracy: 0.6190\n",
            "Epoch 27/30\n",
            "2/2 [==============================] - 2s 547ms/step - loss: 0.3910 - accuracy: 0.8191 - val_loss: 0.9846 - val_accuracy: 0.7619\n",
            "Epoch 28/30\n",
            "2/2 [==============================] - 2s 543ms/step - loss: 0.4248 - accuracy: 0.7819 - val_loss: 0.8348 - val_accuracy: 0.7619\n",
            "Epoch 29/30\n",
            "2/2 [==============================] - 2s 544ms/step - loss: 0.3656 - accuracy: 0.8298 - val_loss: 0.8139 - val_accuracy: 0.6190\n",
            "Epoch 30/30\n",
            "2/2 [==============================] - 2s 541ms/step - loss: 0.3688 - accuracy: 0.8404 - val_loss: 0.8391 - val_accuracy: 0.6190\n",
            "Epoch 1/10\n",
            "2/2 [==============================] - 2s 557ms/step - loss: 0.3623 - accuracy: 0.8298 - val_loss: 0.8644 - val_accuracy: 0.6190\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 1s 529ms/step - loss: 0.3528 - accuracy: 0.8351 - val_loss: 0.8786 - val_accuracy: 0.6190\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 1s 538ms/step - loss: 0.3384 - accuracy: 0.8298 - val_loss: 0.9024 - val_accuracy: 0.7143\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 1s 520ms/step - loss: 0.3444 - accuracy: 0.8298 - val_loss: 0.8158 - val_accuracy: 0.7619\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 1s 530ms/step - loss: 0.3308 - accuracy: 0.8298 - val_loss: 0.7908 - val_accuracy: 0.7619\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 1s 518ms/step - loss: 0.3461 - accuracy: 0.8032 - val_loss: 0.6944 - val_accuracy: 0.6667\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 2s 543ms/step - loss: 0.3348 - accuracy: 0.8404 - val_loss: 0.6815 - val_accuracy: 0.6667\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 2s 541ms/step - loss: 0.3126 - accuracy: 0.8564 - val_loss: 0.6911 - val_accuracy: 0.7143\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 1s 531ms/step - loss: 0.3203 - accuracy: 0.8404 - val_loss: 0.6993 - val_accuracy: 0.7619\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 1s 538ms/step - loss: 0.2813 - accuracy: 0.8617 - val_loss: 0.8597 - val_accuracy: 0.7619\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x23aaa1c3f40>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from keras import backend as K\n",
        "\n",
        "#compile and fit\n",
        "batch_size = 128\n",
        "epochs = 30\n",
        "\n",
        "# use a bigger learning rate than default\n",
        "optimizer = keras.optimizers.Adam(lr=0.01)\n",
        "resnet_model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n",
        "resnet_model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
        "\n",
        "K.set_value(resnet_model.optimizer.learning_rate, 0.001)\n",
        "# fine tuning with a smaller learning rate\n",
        "resnet_model.fit(x_train, y_train, batch_size=batch_size, epochs=10, validation_split=0.1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train loss: 0.4551968276500702  /\\ Train accuracy: 0.7559808492660522\n",
            "Test loss: 1.2162145376205444 /\\ Test accuracy: 0.6000000238418579\n"
          ]
        }
      ],
      "source": [
        "#evaluate\n",
        "training_score = resnet_model.evaluate(x_train, y_train, verbose=0)\n",
        "print(\"Train loss:\", training_score[0], \" /\\ Train accuracy:\", training_score[1])\n",
        "score = resnet_model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0], \"/\\ Test accuracy:\", score[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ROC curves\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Assuming you have a Keras model named 'model' and data (X, y) for binary classification\n",
        "# Split the data into training and test sets\n",
        "# Train your Keras model on the training data\n",
        "\n",
        "# Obtain predicted probabilities for the test set\n",
        "# baseline\n",
        "y_prob_model1 = model.predict(x_test, verbose=False)\n",
        "# tweaked baseline\n",
        "y_prob_model2 = model2.predict(x_test, verbose=False)\n",
        "# more conv layers\n",
        "y_prob_model3 = model3.predict(x_test, verbose=False)\n",
        "# resnet\n",
        "y_prob_resnet = resnet_model.predict(x_test, verbose=False)\n",
        "\n",
        "# compute all ROC and AUC\n",
        "fpr_m1, tpr_m1, thresholds_m1 = roc_curve(non_onehot_y_test, y_prob_model1[:,1])\n",
        "roc_auc_m1 = auc(fpr_m1, tpr_m1)\n",
        "\n",
        "fpr_m2, tpr_m2, thresholds_m2 = roc_curve(non_onehot_y_test, y_prob_model2[:,1])\n",
        "roc_auc_m2 = auc(fpr_m2, tpr_m2)\n",
        "\n",
        "fpr_m3, tpr_m3, thresholds_m3 = roc_curve(non_onehot_y_test, y_prob_model3[:,1])\n",
        "roc_auc_m3 = auc(fpr_m3, tpr_m3)\n",
        "\n",
        "fpr_res, tpr_res, thresholds_res = roc_curve(non_onehot_y_test, y_prob_resnet[:,1])\n",
        "roc_auc_res = auc(fpr_res, tpr_res)\n",
        "\n",
        "\n",
        "# Plot the ROC curve\n",
        "plt.figure(figsize=(10,10))\n",
        "\n",
        "# plotting all the roc_curved\n",
        "plt.plot(fpr_m1, tpr_m1, color='darkorange', lw=2, label='ROC M1 (AUC = {:.2f})'.format(roc_auc_m1))\n",
        "plt.plot(fpr_m2, tpr_m2, color='darkred', lw=2, label='ROC M2 (AUC = {:.2f})'.format(roc_auc_m2))\n",
        "plt.plot(fpr_m3, tpr_m3, color='darkgreen', lw=2, label='ROC M3 (AUC = {:.2f})'.format(roc_auc_m3))\n",
        "plt.plot(fpr_res, tpr_res, color='darkblue', lw=2, label='ROC M4 (AUC = {:.2f})'.format(roc_auc_res))\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Guess')\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BX_LrVY_Fo_q"
      },
      "source": [
        "## 2 Custom training loop (OPTIONAL ARTIN)\n",
        "Replace the fit function by your own tensorflow  implementation\n",
        "\n",
        "- Instantiate one of keras.optimizers to train the model.\n",
        "\n",
        "- Instantiate a loss from keras.losses\n",
        "\n",
        "- Define the metrics (from keras.metrics)\n",
        "\n",
        "- Use `tf.data.Dataset.from_tensor_slices` to create an iterable dataset from a numpy arrays. Do this for the training and test datasets.\n",
        "\n",
        "- Change the model (optional, after the training loop runs to optimize the performance)\n",
        "\n",
        "- Program a loop over a fixed number of epochs,\n",
        "    * For each epoch iterating over the batches\n",
        "    * Within a `GradientTape()` scope,\n",
        "      - do a forward pass on the model for the current batch (call the model on the batch data)\n",
        "      - Compute the loss\n",
        "      - Compute the gradients of the loss w.r.t parameters\n",
        "      - Call the optimimzer to update the weights with computed the gradients\n",
        "    * At the end of each epoch compute the validation metrics\n",
        "\n",
        "\n",
        "Look at https://www.tensorflow.org/tutorials/customization/custom_training_walkthrough specifically at the TRAINING LOOP SECTION\n",
        "for a recent documentation on custom training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Redefining the model to make it \"forget\" the training\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "uMeFjNH64CWD"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\rapha\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:5561: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
            "  output, from_logits = _get_logits(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 0.7054014801979065, Accuracy: 62.67942810058594, Test Loss: 0.6877437829971313, Test Accuracy: 44.0\n",
            "Epoch 2, Loss: 0.6372664570808411, Accuracy: 65.55023956298828, Test Loss: 0.9353318214416504, Test Accuracy: 34.0\n",
            "Epoch 3, Loss: 0.5806545615196228, Accuracy: 65.55023956298828, Test Loss: 0.8009200096130371, Test Accuracy: 34.0\n",
            "Epoch 4, Loss: 0.523252010345459, Accuracy: 69.37799072265625, Test Loss: 0.5472524166107178, Test Accuracy: 76.0\n",
            "Epoch 5, Loss: 0.4831828773021698, Accuracy: 73.20574188232422, Test Loss: 0.5012229681015015, Test Accuracy: 76.0\n",
            "Epoch 6, Loss: 0.4135550856590271, Accuracy: 81.33971405029297, Test Loss: 0.6226404309272766, Test Accuracy: 60.000003814697266\n",
            "Epoch 7, Loss: 0.3639909625053406, Accuracy: 81.33971405029297, Test Loss: 0.6629587411880493, Test Accuracy: 62.0\n",
            "Epoch 8, Loss: 0.3636103570461273, Accuracy: 85.16746520996094, Test Loss: 1.8720717430114746, Test Accuracy: 34.0\n",
            "Epoch 9, Loss: 0.5139673948287964, Accuracy: 76.07655334472656, Test Loss: 0.45528361201286316, Test Accuracy: 84.0\n",
            "Epoch 10, Loss: 0.40553584694862366, Accuracy: 74.64115142822266, Test Loss: 0.5286497473716736, Test Accuracy: 78.0\n",
            "Epoch 11, Loss: 0.35166049003601074, Accuracy: 88.9952163696289, Test Loss: 0.5439473390579224, Test Accuracy: 80.0\n",
            "Epoch 12, Loss: 0.3131307065486908, Accuracy: 88.03827667236328, Test Loss: 0.4602305293083191, Test Accuracy: 90.0\n",
            "Epoch 13, Loss: 0.30944594740867615, Accuracy: 90.43062591552734, Test Loss: 0.7011059522628784, Test Accuracy: 64.0\n",
            "Epoch 14, Loss: 0.259339839220047, Accuracy: 90.90909576416016, Test Loss: 0.5737214088439941, Test Accuracy: 78.0\n",
            "Epoch 15, Loss: 0.23184363543987274, Accuracy: 92.82296752929688, Test Loss: 0.5217235088348389, Test Accuracy: 84.0\n",
            "Epoch 16, Loss: 0.20441211760044098, Accuracy: 94.25837707519531, Test Loss: 0.6143102049827576, Test Accuracy: 74.0\n",
            "Epoch 17, Loss: 0.19175204634666443, Accuracy: 93.7799072265625, Test Loss: 0.6026489734649658, Test Accuracy: 80.0\n",
            "Epoch 18, Loss: 0.16953571140766144, Accuracy: 94.73684692382812, Test Loss: 0.4692428410053253, Test Accuracy: 86.0\n",
            "Epoch 19, Loss: 0.1781311184167862, Accuracy: 94.25837707519531, Test Loss: 0.4554530084133148, Test Accuracy: 88.0\n",
            "Epoch 20, Loss: 0.1313602775335312, Accuracy: 95.69377899169922, Test Loss: 0.6192783117294312, Test Accuracy: 82.0\n",
            "Epoch 21, Loss: 0.12939400970935822, Accuracy: 93.7799072265625, Test Loss: 0.7543148994445801, Test Accuracy: 80.0\n",
            "Epoch 22, Loss: 0.17663238942623138, Accuracy: 93.7799072265625, Test Loss: 0.6938825845718384, Test Accuracy: 84.0\n",
            "Epoch 23, Loss: 0.11671631038188934, Accuracy: 96.17224884033203, Test Loss: 0.5959063172340393, Test Accuracy: 88.0\n",
            "Epoch 24, Loss: 0.09355790168046951, Accuracy: 98.08612823486328, Test Loss: 0.573169469833374, Test Accuracy: 84.0\n",
            "Epoch 25, Loss: 0.08815860748291016, Accuracy: 97.12918090820312, Test Loss: 0.5631351470947266, Test Accuracy: 88.0\n",
            "Epoch 26, Loss: 0.08395244181156158, Accuracy: 98.5645980834961, Test Loss: 0.6033609509468079, Test Accuracy: 86.0\n",
            "Epoch 27, Loss: 0.0766814574599266, Accuracy: 97.60765075683594, Test Loss: 0.5751262903213501, Test Accuracy: 88.0\n",
            "Epoch 28, Loss: 0.06564398109912872, Accuracy: 98.5645980834961, Test Loss: 0.6108291149139404, Test Accuracy: 90.0\n",
            "Epoch 29, Loss: 0.0699840784072876, Accuracy: 98.5645980834961, Test Loss: 0.6682863235473633, Test Accuracy: 88.0\n",
            "Epoch 30, Loss: 0.07983656972646713, Accuracy: 97.60765075683594, Test Loss: 0.7293145656585693, Test Accuracy: 80.0\n",
            "Epoch 31, Loss: 0.053954117000103, Accuracy: 100.0, Test Loss: 0.6656032800674438, Test Accuracy: 80.0\n",
            "Epoch 32, Loss: 0.06523284316062927, Accuracy: 99.52153015136719, Test Loss: 0.6465039849281311, Test Accuracy: 86.0\n",
            "Epoch 33, Loss: 0.04599826782941818, Accuracy: 99.52153015136719, Test Loss: 0.784565269947052, Test Accuracy: 84.0\n",
            "Epoch 34, Loss: 0.043402086943387985, Accuracy: 100.0, Test Loss: 0.7521815896034241, Test Accuracy: 84.0\n",
            "Epoch 35, Loss: 0.03999028354883194, Accuracy: 100.0, Test Loss: 0.8273537158966064, Test Accuracy: 80.0\n",
            "Epoch 36, Loss: 0.03265104070305824, Accuracy: 100.0, Test Loss: 0.7224105596542358, Test Accuracy: 84.0\n",
            "Epoch 37, Loss: 0.03849250078201294, Accuracy: 99.52153015136719, Test Loss: 0.7101000547409058, Test Accuracy: 86.0\n",
            "Epoch 38, Loss: 0.03545656055212021, Accuracy: 99.52153015136719, Test Loss: 0.7487708330154419, Test Accuracy: 86.0\n",
            "Epoch 39, Loss: 0.021968083456158638, Accuracy: 100.0, Test Loss: 0.7087239027023315, Test Accuracy: 86.0\n",
            "Epoch 40, Loss: 0.02903175726532936, Accuracy: 100.0, Test Loss: 0.7433056831359863, Test Accuracy: 84.0\n",
            "Epoch 41, Loss: 0.018647326156497, Accuracy: 100.0, Test Loss: 0.7259559631347656, Test Accuracy: 86.0\n",
            "Epoch 42, Loss: 0.02055557444691658, Accuracy: 100.0, Test Loss: 0.7307419776916504, Test Accuracy: 86.0\n",
            "Epoch 43, Loss: 0.022618576884269714, Accuracy: 100.0, Test Loss: 0.8306014537811279, Test Accuracy: 84.0\n",
            "Epoch 44, Loss: 0.020494388416409492, Accuracy: 100.0, Test Loss: 0.9376226663589478, Test Accuracy: 82.0\n",
            "Epoch 45, Loss: 0.02205854468047619, Accuracy: 99.52153015136719, Test Loss: 0.8920348882675171, Test Accuracy: 80.0\n",
            "Epoch 46, Loss: 0.028367772698402405, Accuracy: 100.0, Test Loss: 0.7659649848937988, Test Accuracy: 88.0\n",
            "Epoch 47, Loss: 0.016518307849764824, Accuracy: 100.0, Test Loss: 0.7890386581420898, Test Accuracy: 86.0\n",
            "Epoch 48, Loss: 0.014895902946591377, Accuracy: 100.0, Test Loss: 0.8350204229354858, Test Accuracy: 82.0\n",
            "Epoch 49, Loss: 0.013309618458151817, Accuracy: 100.0, Test Loss: 0.9325927495956421, Test Accuracy: 84.0\n",
            "Epoch 50, Loss: 0.024727357551455498, Accuracy: 100.0, Test Loss: 0.8090568780899048, Test Accuracy: 84.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Convert the training and test data to tf.data.Dataset objects\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size=1024).batch(32)\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(32)\n",
        "\n",
        "# Instantiate a model, optimizer, and loss function\n",
        "# here redefining my current model with the first model used (baseline)\n",
        "model = model\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
        "test_accuracy = tf.keras.metrics.CategoricalAccuracy(name='test_accuracy')\n",
        "\n",
        "# Defining my own train_step function that is called during the training of keras\n",
        "# Overwriting the tf function\n",
        "@tf.function\n",
        "def train_step(images, labels):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(images, training=True)\n",
        "        loss = loss_object(labels, predictions)\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    train_loss(loss)\n",
        "    train_accuracy(labels, predictions)\n",
        "\n",
        "# Same for the test \n",
        "@tf.function\n",
        "def test_step(images, labels):\n",
        "    predictions = model(images, training=False)\n",
        "    t_loss = loss_object(labels, predictions)\n",
        "\n",
        "    test_loss(t_loss)\n",
        "    test_accuracy(labels, predictions)\n",
        "\n",
        "# Training loop\n",
        "# definining the number of epochs for which I want to train my model\n",
        "epochs = 50\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    # Reset the metrics at the start of the next epoch\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    test_accuracy.reset_states()\n",
        "\n",
        "    # iterating through the images and using the training step previoyusly defined\n",
        "    for images, labels in train_dataset:\n",
        "        train_step(images, labels)\n",
        "\n",
        "    for test_images, test_labels in test_dataset:\n",
        "        test_step(test_images, test_labels)\n",
        "\n",
        "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
        "    print(template.format(epoch+1,\n",
        "                          train_loss.result(),\n",
        "                          train_accuracy.result()*100,\n",
        "                          test_loss.result(),\n",
        "                          test_accuracy.result()*100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zd77rWJY4Eon"
      },
      "source": [
        "ADITIONAL BONUS\n",
        "- Early stopping\n",
        "- Tensorboard\n",
        "- CAM/GradCAM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Redefining the model to make it \"forget\" the training\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input(shape=input_shape),\n",
        "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
        "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(num_classes, activation=\"sigmoid\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "K-PQ71UOFo_r"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "6/6 [==============================] - 1s 58ms/step - loss: 0.6624 - accuracy: 0.5957 - val_loss: 0.5695 - val_accuracy: 0.8095\n",
            "Epoch 2/30\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 0.5974 - accuracy: 0.6383 - val_loss: 0.4966 - val_accuracy: 0.8095\n",
            "Epoch 3/30\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.5389 - accuracy: 0.6383 - val_loss: 0.4722 - val_accuracy: 0.8095\n",
            "Epoch 4/30\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.4950 - accuracy: 0.6862 - val_loss: 0.4959 - val_accuracy: 0.7143\n",
            "Epoch 5/30\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.4496 - accuracy: 0.7713 - val_loss: 0.5245 - val_accuracy: 0.8095\n",
            "Epoch 6/30\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.4694 - accuracy: 0.7287 - val_loss: 0.5680 - val_accuracy: 0.7143\n",
            "Epoch 7/30\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.4363 - accuracy: 0.7394 - val_loss: 0.5531 - val_accuracy: 0.7143\n",
            "Epoch 8/30\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.3949 - accuracy: 0.8298 - val_loss: 0.5642 - val_accuracy: 0.7619\n",
            "Epoch 9/30\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.3730 - accuracy: 0.8138 - val_loss: 0.5956 - val_accuracy: 0.6667\n",
            "Epoch 10/30\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.3408 - accuracy: 0.8777 - val_loss: 0.6438 - val_accuracy: 0.7143\n",
            "Epoch 11/30\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.3236 - accuracy: 0.8564 - val_loss: 0.6466 - val_accuracy: 0.6190\n"
          ]
        }
      ],
      "source": [
        "# defining when the model should stop, here when the val_loss doesn't get better\n",
        "# creating the early stopping and tensorboard callbacks\n",
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=8)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"./logs\")\n",
        "batch_size = 32\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "history = model.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=30,  # Assume some large number of epochs\n",
        "    batch_size=batch_size, \n",
        "    validation_split=0.1,\n",
        "    callbacks=[early_stopping_callback, tensorboard_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Reusing TensorBoard on port 6006 (pid 15996), started 0:20:38 ago. (Use '!kill 15996' to kill it.)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-f4038a1e3d2e4f9e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-f4038a1e3d2e4f9e\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir logs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
